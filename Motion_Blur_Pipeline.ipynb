{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Motion_Blur_Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvb/LFAgrDgiFTpS+uyhCJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bes82/Motion_Blur/blob/main/Motion_Blur_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfpITcI-uBKG"
      },
      "source": [
        "## Import libraries, download network, and load network.\n",
        "\n",
        "This cell has three jobs. \n",
        "\n",
        "1.) Import useful libraries for use during the pipeline.\n",
        "\n",
        "2.) Download the pipeline network architecture and weights from a Google Drive.\n",
        "\n",
        "3.) Load the network for use in the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjlPGWcKuAtM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "45c58398-5a57-4cc1-b97e-36b5cb666950"
      },
      "source": [
        "#@title  <- Click here to run code. Double click this text to see code. \n",
        "print(\"Importing Useful Libraries...\")\n",
        "# Importing Useful Libraries.\n",
        "import tensorflow.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import cv2, os\n",
        "from scipy.ndimage import label\n",
        "from skimage import measure\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "import shutil\n",
        "print(\"Done!\")\n",
        "\n",
        "# Clone Repository And Download Network Architecture and Weights.\n",
        "print(\"Cloning Repository...\")\n",
        "! git clone https://github.com/bes82/Motion_Blur\n",
        "print(\"Done!\")\n",
        "%cd Motion_Blur\n",
        "print(\"Downloading Network Architecture And Weights...\")\n",
        "!gdown --id \"1pwyHkF4190pLYMvuzHITzNCNuynx7LCA\"\n",
        "print(\"Done!\")\n",
        "\n",
        "# Load Downloaded Network Architecture And Weights.\n",
        "print(\"Loading Network Architecture and Weights...\")\n",
        "network_Name = \"Motion_Blur_Network.h5\"\n",
        "network = tf.keras.models.load_model(network_Name)\n",
        "print(\"Done!\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Importing Useful Libraries...\n",
            "Done!\n",
            "Cloning Repository...\n",
            "Cloning into 'Motion_Blur'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 14 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (14/14), done.\n",
            "Done!\n",
            "/content/Motion_Blur\n",
            "Downloading Network Architecture And Weights...\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pwyHkF4190pLYMvuzHITzNCNuynx7LCA\n",
            "To: /content/Motion_Blur/Motion_Blur_Network.h5\n",
            "190MB [00:02, 85.6MB/s]\n",
            "Done!\n",
            "Loading Network Architecture and Weights...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJD48Uj_uqE3"
      },
      "source": [
        "## Create directory to hold channels for analysis.\n",
        "\n",
        "This cell is used to create a directory that will hold channels that we want to analyze.\n",
        "\n",
        "IMPORTANT: Once this cell is run, you will need to manually upload channel images to the directory titled \"Motion_Blur/Channel_Directory\". \n",
        "\n",
        "If you want to re-initialize the directory, then just re-run this code after analyzing your first batch of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "oroLaZ28nA4Y"
      },
      "source": [
        "#@title <- Click here to run code. Double click this text to view code.\n",
        "# Create A Directory To Hold Channels For Analysis.\n",
        "channel_Directory = \"Channel_Directory/\"\n",
        "if os.path.isdir(channel_Directory):\n",
        "  shutil.rmtree(channel_Directory)\n",
        "os.mkdir(channel_Directory)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dd9vxNnvw8U"
      },
      "source": [
        "## Channel Analysis.\n",
        "\n",
        "This cell applies analysis to all of the channels uploaded to the \"Motion_Blur/Channel_Directory\" directory. After each channel is analyzed, the sRBC counts are appended to a data frame and displayed to the user.\n",
        "\n",
        "After all channels are analyzed, the final dataframe is displayed to the user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "cellView": "form",
        "id": "gKFNd16rOXKi",
        "outputId": "936046a0-43d8-4fb0-c09a-5a1849e0ac5f"
      },
      "source": [
        "#@title <- Click here to run code. Double click this text to view code.\n",
        "# An array to hold pixel areas for all tested channels.\n",
        "blob_Sizes = []\n",
        "output_Data_Frame = pd.DataFrame(columns = [\"File Name\", \"sRBC Counts\", \"Time (s)\"])\n",
        "# A function which applies a zero mean normalization to the input images.\n",
        "def standard_norm(img):\n",
        "    height, width, channels = img.shape\n",
        "    for channel in range(channels):\n",
        "        img[:,:,channel] = (img[:,:,channel] - np.mean(img[:,:,channel]))/np.std(img[:,:,channel])\n",
        "    return img\n",
        "\n",
        "# Thresholds to be tested.\n",
        "thresholds = [90]\n",
        "\n",
        "# This large for loop will analyze all of the channels uploaded to the Channel Directory.\n",
        "for image_Name in os.listdir(channel_Directory):\n",
        "    # If statement necessary to avoid possible errors during analysis on Google Colab.\n",
        "    if \".ipynb\" in image_Name:\n",
        "      continue\n",
        "    # Start time of analysis.\n",
        "    start_Time = time.time()\n",
        "    print(\"Analyzing \" + image_Name[:-4])\n",
        "    # Reading In Channel.\n",
        "    full_Channel = plt.imread(channel_Directory + image_Name)\n",
        "    # Convert grayscale image to RGB if the input channel is grayscale.\n",
        "    if len(np.shape(full_Channel)) == 2:\n",
        "        full_Channel = cv2.cvtColor(full_Channel, cv2.COLOR_GRAY2RGB)\n",
        "    # Defining characteristics of the input channel.\n",
        "    image_Height, image_Width, channels = np.shape(full_Channel)\n",
        "    # The following if statements are used to resize the channel to have\n",
        "    # dimensions which are evenly dividable by 150. To avoid as much distortion\n",
        "    # as possible, we will resize either up or down in each dimensions, \n",
        "    # depending on which end the dimensions is closer to.\n",
        "    if (image_Height % 150) < 75 and (image_Width % 150) < 75:\n",
        "        full_Channel_Resized = cv2.resize(full_Channel,(int(np.floor(image_Width/150)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
        "        vertical_Tiles = int(np.floor(image_Height/150))\n",
        "        horizontal_Tiles = int(np.floor(image_Width/150))\n",
        "    elif (image_Height % 150) >= 75 and (image_Width % 150) >= 75:\n",
        "        full_Channel_Resized = cv2.resize(full_Channel,(int((np.floor(image_Width/150) + 1)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
        "        vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
        "        horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
        "    elif (image_Height % 150) >= 75 and (image_Width % 150) < 75:\n",
        "        full_Channel_Resized = cv2.resize(full_Channel,(int(np.floor(image_Width/150)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
        "        vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
        "        horizontal_Tiles = int(np.floor(image_Width/150))\n",
        "    else:\n",
        "        full_Channel_Resized = cv2.resize(full_Channel,(int((np.floor(image_Width/150) + 1)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
        "        vertical_Tiles = int(np.floor(image_Height/150))\n",
        "        horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
        "    # Defining characteristics of the resized input channel.\n",
        "    image_Height_Resized, image_Width_Resized, channels = np.shape(full_Channel_Resized)\n",
        "    # Creating an array which will hold predictions.\n",
        "    output_Image = np.zeros((image_Height_Resized,image_Width_Resized))\n",
        "\n",
        "    # The following chunk of code will make predictions, and create output\n",
        "    # images and mask predictions.\n",
        "    x_Slider = 0\n",
        "    y_Slider = 0\n",
        "    # Creating an array which will hold predictions for each tile.\n",
        "    output_Array = np.zeros((128,128))\n",
        "    # In the following for loops, we will slide through the input channel, \n",
        "    # tile by tile, and make predictions on each tile.\n",
        "    for i in range(vertical_Tiles):\n",
        "        x_Slider = 150*i\n",
        "        # Sliding through all tiles in a row for each row.\n",
        "        for j in range(horizontal_Tiles):\n",
        "            y_Slider = 150*j\n",
        "            # Resizing tile to required input size.\n",
        "            current_Tile = full_Channel_Resized[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150,:]/255\n",
        "            current_Tile = cv2.resize(current_Tile, (128,128), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            # Normalizing the tile.\n",
        "            current_Tile_Normalized = standard_norm(current_Tile.copy())\n",
        "            current_Tile_Normalized = current_Tile_Normalized[None,:,:,:]\n",
        "            output = network.predict(current_Tile_Normalized)\n",
        "\n",
        "            # Finding the prediction for each pixel in the tile.\n",
        "            for i in range(128):\n",
        "                for j in range(128):\n",
        "                    output_Array[i,j] = np.argmax(output[0,i,j,:])\n",
        "            \n",
        "            # Resizing tile back to original size.\n",
        "            output_Array = cv2.resize(output_Array,(150,150),interpolation = cv2.INTER_AREA)\n",
        "            output_Image[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150] = output_Array\n",
        "            output_Array = np.zeros((128,128))\n",
        "    # The following for loops binarize the output, after resizing distortion.\n",
        "    for i in range(image_Height_Resized):\n",
        "        for j in range(image_Width_Resized):\n",
        "            if output_Image[i,j] != 0:\n",
        "                output_Image[i,j] = 1\n",
        "            else:\n",
        "                continue\n",
        "    # The end time for a channel analysis.\n",
        "    end_Time = time.time()\n",
        "    time_Change = end_Time - start_Time\n",
        "\n",
        "    # Defining connected pixel regions in the final image.\n",
        "    blobs, number_Of_Blobs = label(output_Image)\n",
        "    properties = measure.regionprops(blobs)\n",
        "    # Appending pixel area sizes to a list.\n",
        "    for prop in properties:\n",
        "        blob_Sizes.append(prop.area)\n",
        "    # If a pixel area is greater than a threshold, the connected region\n",
        "    # is counted as an sRBC.\n",
        "    for thresh in thresholds:\n",
        "        centroids = [prop.centroid for prop in properties if prop.area > thresh]\n",
        "        output_Data_Frame = output_Data_Frame.append(pd.DataFrame([[image_Name,len(centroids),time_Change]], columns = [\"File Name\", \"sRBC Counts\", \"Time (s)\"]))\n",
        "    display(output_Data_Frame)\n",
        "    print(\"======================================\")\n",
        "\n",
        "print(\"Final Data\")\n",
        "display(output_Data_Frame)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analyzing 20201219-UPN236-R1-9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Name</th>\n",
              "      <th>sRBC Counts</th>\n",
              "      <th>Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20201219-UPN236-R1-9.jpg</td>\n",
              "      <td>55</td>\n",
              "      <td>66.629881</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  File Name sRBC Counts   Time (s)\n",
              "0  20201219-UPN236-R1-9.jpg          55  66.629881"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "======================================\n",
            "Analyzing 20201219-UPN236-R2-9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Name</th>\n",
              "      <th>sRBC Counts</th>\n",
              "      <th>Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20201219-UPN236-R1-9.jpg</td>\n",
              "      <td>55</td>\n",
              "      <td>66.629881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20201219-UPN236-R2-9.jpg</td>\n",
              "      <td>149</td>\n",
              "      <td>65.658281</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  File Name sRBC Counts   Time (s)\n",
              "0  20201219-UPN236-R1-9.jpg          55  66.629881\n",
              "0  20201219-UPN236-R2-9.jpg         149  65.658281"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "======================================\n",
            "Analyzing 20201219-UPN98-R4-15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Name</th>\n",
              "      <th>sRBC Counts</th>\n",
              "      <th>Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20201219-UPN236-R1-9.jpg</td>\n",
              "      <td>55</td>\n",
              "      <td>66.629881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20201219-UPN236-R2-9.jpg</td>\n",
              "      <td>149</td>\n",
              "      <td>65.658281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20201219-UPN98-R4-15.jpg</td>\n",
              "      <td>350</td>\n",
              "      <td>195.124059</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  File Name sRBC Counts    Time (s)\n",
              "0  20201219-UPN236-R1-9.jpg          55   66.629881\n",
              "0  20201219-UPN236-R2-9.jpg         149   65.658281\n",
              "0  20201219-UPN98-R4-15.jpg         350  195.124059"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "======================================\n",
            "Analyzing 20201219-UPN98-R3-17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Name</th>\n",
              "      <th>sRBC Counts</th>\n",
              "      <th>Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20201219-UPN236-R1-9.jpg</td>\n",
              "      <td>55</td>\n",
              "      <td>66.629881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20201219-UPN236-R2-9.jpg</td>\n",
              "      <td>149</td>\n",
              "      <td>65.658281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20201219-UPN98-R4-15.jpg</td>\n",
              "      <td>350</td>\n",
              "      <td>195.124059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20201219-UPN98-R3-17.jpg</td>\n",
              "      <td>1582</td>\n",
              "      <td>189.118432</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  File Name sRBC Counts    Time (s)\n",
              "0  20201219-UPN236-R1-9.jpg          55   66.629881\n",
              "0  20201219-UPN236-R2-9.jpg         149   65.658281\n",
              "0  20201219-UPN98-R4-15.jpg         350  195.124059\n",
              "0  20201219-UPN98-R3-17.jpg        1582  189.118432"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "======================================\n",
            "Analyzing 20201219-UPN98-R3-19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-71b8aa757463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mcurrent_Tile_Normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_Tile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mcurrent_Tile_Normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_Tile_Normalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_Tile_Normalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# Finding the prediction for each pixel in the tile.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1623\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2970\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 2972\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   2973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}