{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoafuG4JIb8WeKwE4mK+p7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bes82/Motion_Blur/blob/main/Training_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK3nOu0UGy_t"
      },
      "source": [
        "## Import libraries, unzip files.\n",
        "\n",
        "This cell has two jobs. \n",
        "\n",
        "1.) Import useful libraries for use during the training.\n",
        "\n",
        "2.) Unzip all images and arrays that will be used for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT2ubUYhLRph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "8a0219c0-78e8-4cd4-cc72-e50f9f2cc09b"
      },
      "source": [
        "#@title <- Click here to run code. Double click this text to see code. \n",
        "# Import necessary functions.\n",
        "\n",
        "import pandas as pd\n",
        "import os as os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Clone Repository And Download Network Architecture and Weights.\n",
        "print(\"Cloning Repository...\")\n",
        "! git clone https://github.com/bes82/Motion_Blur\n",
        "print(\"Done!\")\n",
        "%cd Motion_Blur\n",
        "\n",
        "# Defining zip-file names.\n",
        "from zipfile import ZipFile\n",
        "folder_Names = [\"Flow_Folder.zip\",\"Layered_And_Labeled_Tiles_Resized.zip\",\"Original_Image_Tiles_Resized.zip\"]\n",
        "  \n",
        "# specifying the zip file name\n",
        "for file_name in folder_Names:\n",
        "    \n",
        "  # opening the zip file in READ mode\n",
        "  with ZipFile(file_name, 'r') as zip:\n",
        "      # extracting all the files\n",
        "      print('Extracting all the files from ' + str(file_name) + \" now...\")\n",
        "      zip.extractall()\n",
        "      print('Done!')\n",
        "# Define source for original tiles and ground truth masks for training. \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning Repository...\n",
            "Cloning into 'Motion_Blur'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 68 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (68/68), done.\n",
            "Done!\n",
            "/content/Motion_Blur\n",
            "Extracting all the files from Flow_Folder.zip now...\n",
            "Done!\n",
            "Extracting all the files from Layered_And_Labeled_Tiles_Resized.zip now...\n",
            "Done!\n",
            "Extracting all the files from Original_Image_Tiles_Resized.zip now...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtpwNAnqIXJh"
      },
      "source": [
        "## Train the network.\n",
        "\n",
        "The following cell will train the network using the images unzipped in the previous cell. Each epoch will be displayed dynamically, letting the user see the progress of training. \n",
        "\n",
        "The network will stop training after five consecutive epochs with no decrease in the validation loss. \n",
        "\n",
        "After training is completed, the network will be saved with the name \"Motion_Blur_Network.h5\" to the \"Motion_Blur\" directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "-Pijf3FznUT6",
        "outputId": "736b9ce7-0027-4ee0-d53c-0fc68a13ebe6"
      },
      "source": [
        "#@title <- Click here to run code. Double click this text to see code. \n",
        "# This chunk of code is used to complete the training of a network which will be used to classify pixels of whole channel\n",
        "# images.\n",
        "\n",
        "# Loading useful classes and functions for use in training.\n",
        "from train_source import DataGenerator\n",
        "from train_source import Phase1_Net\n",
        "\n",
        "# Defining paths for a directory of images/masks and also for the data frame of file names.\n",
        "flow_Directory = \"Flow_Folder/\"\n",
        "data_Frame_Location = \"Training_Data_Frame_Motion_Blur.csv\"\n",
        "\n",
        "# Read in data frame.\n",
        "training_Data_Frame = pd.read_csv(data_Frame_Location)\n",
        "\n",
        "# Defining the framework for how files are named for training.\n",
        "tile_Names_Style = \"Original_Tiles_Resized\" \n",
        "mask_Names_Style = \"Layer_Labeled_Resized\"\n",
        "\n",
        "# Input size for the network.\n",
        "img_size = (128,128)\n",
        "\n",
        "indices = np.arange(1500) + 1\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Number of classes for classification.\n",
        "num_classes = 2\n",
        "number_Of_Epochs = 200\n",
        "\n",
        "# Creating the model.\n",
        "model = Phase1_Net(img_size, num_classes)\n",
        "\n",
        "# Creating a callback function for stopping training after no improvement for a set amount of epochs.\n",
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=5, verbose=2,\n",
        "    mode='auto', baseline=None, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Compiling the network architecture.\n",
        "model.compile(Adam(lr=0.001),\n",
        "                 metrics = ['accuracy'],\n",
        "                 loss = tf.keras.losses.CategoricalCrossentropy())\n",
        "\n",
        "# Defining the generator which will read in tiles for training in small batches, so we don't use too much RAM.\n",
        "train_Gen = DataGenerator(data_Frame=training_Data_Frame,\n",
        "                    x_Col = \"X\",\n",
        "                    y_Col = \"Y_True\",\n",
        "                    directory = flow_Directory,\n",
        "                    vertical_Flips=True,\n",
        "                    horizontal_Flips = True,\n",
        "                    rotations = True,\n",
        "                    split = True,\n",
        "                    training_Ratio = 0.8,\n",
        "                    shuffle = True,\n",
        "                    tile_Namesake = tile_Names_Style,\n",
        "                    mask_Namesake = mask_Names_Style,\n",
        "                    subset = \"Training\",\n",
        "                    number_Of_Classes = num_classes,\n",
        "                         indices = indices)\n",
        "\n",
        "# Defining the generator which will read in tiles for validation in small batches, so we don't use too much RAM.\n",
        "validate_Gen = DataGenerator(data_Frame=training_Data_Frame,\n",
        "                    x_Col = \"X\",\n",
        "                    y_Col = \"Y_True\",\n",
        "                    directory = flow_Directory,\n",
        "                    vertical_Flips=False,\n",
        "                    horizontal_Flips = False,\n",
        "                    rotations = False,\n",
        "                    split = True,\n",
        "                    training_Ratio = 0.8,\n",
        "                    shuffle = True,\n",
        "                    tile_Namesake = tile_Names_Style,\n",
        "                    mask_Namesake = mask_Names_Style,\n",
        "                    subset = \"Validation\",\n",
        "                    number_Of_Classes = num_classes,\n",
        "                            indices = indices)\n",
        "\n",
        "# Fitting the hyperparameters of the model.\n",
        "training_History = model.fit(train_Gen,\n",
        "                             validation_data = validate_Gen,\n",
        "                                 epochs=number_Of_Epochs, \n",
        "                                 verbose = 1, callbacks = [callback])\n",
        "\n",
        "# Save the architecture and weights as a .h5 file.\n",
        "model_Name = \"Motion_Blur_Network.h5\"\n",
        "model.save(model_Name)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No errors for filter size:256\n",
            "No errors for filter size:512\n",
            "No errors for filter size:512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "37/37 [==============================] - 830s 22s/step - loss: 0.5180 - accuracy: 0.8674 - val_loss: 0.1460 - val_accuracy: 0.9848\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 822s 22s/step - loss: 0.3059 - accuracy: 0.9864 - val_loss: 0.0628 - val_accuracy: 0.9968\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 821s 22s/step - loss: 0.1726 - accuracy: 0.9886 - val_loss: 0.0403 - val_accuracy: 0.9968\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 820s 22s/step - loss: 0.1021 - accuracy: 0.9886 - val_loss: 0.0282 - val_accuracy: 0.9968\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 824s 22s/step - loss: 0.0689 - accuracy: 0.9885 - val_loss: 0.0224 - val_accuracy: 0.9968\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 822s 22s/step - loss: 0.0516 - accuracy: 0.9885 - val_loss: 0.0181 - val_accuracy: 0.9968\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 822s 22s/step - loss: 0.0411 - accuracy: 0.9884 - val_loss: 0.0133 - val_accuracy: 0.9968\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 820s 22s/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.0137 - val_accuracy: 0.9968\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1N44zkzNCbP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}